<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haihong Xiao</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Haihong Xiao
                </p>
                <p>I'm a PhD student at <a href="https://www.scut.edu.cn/en/"> South China University of Technology</a>, Department of School of Automation Science and Engineering, supervised by Professor <a href="https://www.scholat.com/auwxkang">Wenxiong Kang</a>. My research interests lie in 3D Vision, scene representation learning, point cloud processing, and plant phenotyping analysis. I've received the <a href="https://www2.scut.edu.cn/automation/_t1155/2024/0929/c36672a563516/page.htm">National Scholarship (2024) </a>
                </p>
                <p>
                  In 2023-2024, I was a CSC-funded visiting PhD student at <a href="https://www.scut.edu.cn/en/">Nanyang Technological University</a>, Singapore, supervised by Professor <a href="https://personal.ntu.edu.sg/yhe/">Ying He</a>. My research focused on real-time rendering and geometric learning.
               </p>
                <p style="text-align:center">
                   Email: hhxiaowv at gmail dot com &nbsp;/&nbsp;
                  <a href="data/hhx_cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=8AV-HUYAAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://orcid.org/0000-0002-3543-9262">ORCID</a> &nbsp;/&nbsp;
                  <a href="https://github.com/SuperDouble">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:16%;max-width:16%">
                <a href="images/xhh_images/1_self_xhh.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/xhh_images/1_self_xhh.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Recent Research</h2>
                <p>
                  In the past five years, my first-authored and co-authored publications are listed below, with <strong>*</strong> denoting equivalent contribution.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
       <!-- <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/ever_after.png' width=100%>
					</div>
          <img src='images/ever_before.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ever.github.io/">
			<span class="papertitle">EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis
</span>
        </a>
        <br>
				<a href="https://half-potato.gitlab.io/">Alexander Mai</a>, 
				<a href="https://phogzone.com/">Peter Hedman</a>,
				<a href="https://grgkopanas.github.io/">George Kopanas</a>,
        <a href="https://dorverbin.github.io/">Dor Verbin</a>,
        <a href="https://scholar.google.com/citations?user=ozNFrecAAAAJ&hl=en">David Futschik</a>,
        <a href="https://xharlie.github.io/">Qiangeng Xu</a>,
        <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://www.zhangyinda.com/">Yinda Zhang</a>
				<br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://half-potato.gitlab.io/posts/ever/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
        <p></p>
        <p>
				Raytracing constant-density ellipsoids yields more accurate and flexible radiance fields than splatting Gaussians, and still runs in real-time.
        </p>
      </td>
    </tr>
     -->
<tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/xhh_images/2_ja.png" alt="clean-usnob" width="160" height="90">
    </td>
    <td width="75%" valign="middle">
        <!--
<a href="https://ieeexplore.ieee.org/document/10601197">
-->
        <span class="papertitle">Geometry-Aware 3D Gaussian Representation for Real-Time Rendering of Large-Scale Scenes</span>
        </a>
        <br>
        <strong>Haihong Xiao*, Jianan Zou*</strong>, Shuai Xing, Pengcheng Li, Wenxiong Kang
        <br>
        <em>IEEE Transactions on Multimedia (TMM), major revision</em>, 2024
        <p>We introduce a novel geometry-aware 3DGS method for efficient real-time rendering of large scenes.</p>
    </td>
</tr>

<tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/xhh_images/2_yp.png" alt="clean-usnob" width="160" height="90">
    </td>
    <td width="75%" valign="middle">
        <!--
<a href="https://ieeexplore.ieee.org/document/10601197">
-->
        <span class="papertitle">Tri2plane: Advancing Neural Implicit Surface Reconstruction for Indoor Scenes</span>
        </a>
        <br>
        <strong>Yiping Xie*, Haihong Xiao*</strong>, Wenxiong Kang
        <br>
        <em>IEEE Transactions on Multimedia (TMM), major revision</em>, 2024
        <p>We introduce a novel triangle-based triplane representation, named (Tri2plane), specifically designed to account for the diverse spatial feature distribution and information density of indoor environments.</p>
    </td>
</tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/xhh_images/2_jl.png" alt="clean-usnob" width="160" height="90">
        </td>
        <td width="75%" valign="middle">
            <!--
<a href="https://ieeexplore.ieee.org/document/10601197">
-->
            <span class="papertitle">EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes</span>
            </a>
            <br>
            <strong>Jianlin Guo*, Haihong Xiao*</strong>, Jianan Zou, Feiqi Deng, Wenxiong Kang
    <br>
    <em>IEEE Transactions on Geoscience and Remote Sensing (TGRS), under review</em>, 2024
    <p>We propose EA-3DGS, a high-quality real-time rendering method designed for outdoor scenes.</p>
</td>
    </tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/xhh_images/2_ssc.png" alt="clean-usnob" width="160" height="90">
        </td>
        <td width="75%" valign="middle">
            <!--
           <a href="https://ieeexplore.ieee.org/document/10601197">    
            -->
                <span class="papertitle">Semantic Scene Completion via Semantic-aware Guidance and Interactive Refinement Transformer</span>
            </a>
            <br>
            <strong>Haihong Xiao</strong>, Wenxiong Kang, Hao Liu, Yuqiong Li, Ying He
            <br>
            <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), minor revision</em>, 2024
            <p>This work aimed to mitigate the negative impacts of incorrect voxel query proposals caused by erroneous depth estimates and enhance interactions for positive ones in camera-based semantic scene completion tasks.</p>
        </td>
    </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/xhh_images/2_ea_mvs.png" alt="clean-usnob" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/10601197">
                    <span class="papertitle">EA-MVSNet: Learning Error-Awareness for Enhanced Multi-View Stereo</span>
                </a>
                <br>
                <strong>Wencong Gu*, Haihong Xiao*</strong>, Xueyan Zhao, Wenxiong Kang
                <br>
                <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2024
                <p>We present a novel error-aware depth representation that enhances depth prediction accuracy through error-aware learning.</p>
            </td>
        </tr>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/xhh_images/2_spv.png" alt="clean-usnob" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/10589366">
                    <span class="papertitle">Point Cloud Completion via Self-projected View Augmentation and Implicit Field Constraint</span>
                </a>
                <br>
                <strong>Haihong Xiao</strong>, Ying He, Hao Liu, Wenxiong Kang, Yuqiong Li
                <br>
                <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2024
                <p> We propose a point cloud completion method that leverages self-projected view augmentation and implicit field constraints.</p>
            </td>
        </tr>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/xhh_images/2_iam.png" alt="clean-usnob" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/10379527">
                    <span class="papertitle">Instance-Aware Monocular 3D Semantic Scene Completion</span>
                </a>
                <br>
                <strong>Haihong Xiao</strong>, Hongbin Xu, Wenxiong Kang, Yuqiong Li
                <br>
                <em>IEEE Transactions on Intelligent Transportation Systems (TITS)</em>, 2024
                <p> We study outdoor 3D scene understanding, a challenging task demanding the intelligent system to infer both geometry and semantics from a single-view image.</p>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/xhh_images/2_tfc.png" alt="clean-usnob" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/10411836">
                    <span class="papertitle">Text-Free Controllable 3-D Point Cloud Generation</span>
                </a>
                <br>
                <strong>Haihong Xiao</strong>, Wenxiong Kang, Yuqiong Li, Hongbin Xu
                <br>
                <em>IEEE Transactions on Instrumentation and Measurement (TIM)</em>, 2024
                <p>We present TFCNet, a approach for text-free controllable point cloud generation.</p>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/xhh_images/2_dmt.png" alt="clean-usnob" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/10056970">
                    <span class="papertitle">Distinguishing and Matching-Aware Unsupervised Point Cloud Completion</span>
                </a>
                <br>
                <strong>Haihong Xiao</strong>, Yuqiong Li, Wenxiong Kang, Qiuxia Wu
                <br>
                <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2023
                <p>We propose DMNet, a distinguishing and matching-aware unsupervised point cloud completion network without extensive paired training data.</p>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/xhh_images/2_mdg.png" alt="clean-usnob" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/9978708">
                    <span class="papertitle">Multi-Dimensional Graph Interactional Network for Progressive Point Cloud Completion</span>
                </a>
                <br>
                <strong>Haihong Xiao</strong>, Hongbin Xu, Wenxiong Kang, Yuqiong Li
                <br>
                <em>IEEE Transactions on Instrumentation and Measurement (TIM)</em>, 2023
                <p>We design a depth map discriminator combined with differentiable rendering to match the distribution of generated and real point clouds.</p>
            </td>
        </tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/xhh_images/2_pdc.jpg" alt="clean-usnob" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
            <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.html">
                <span class="papertitle">PointDC: Unsupervised Semantic Segmentation of 3D Point Clouds via Cross-modal Distillation and Super-Voxel Clustering</span>
            </a>
            <br>
            Zisheng Chen, Hongbin Xu, Weitao Chen, Zhipeng Zhou, <strong>Haihong Xiao</strong>, Baigui Sun, Xuansong Xie
            <br>
            <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023
            <p>We take the first attempt for fully unsupervised semantic segmentation of point clouds, which aims to delineate semantically meaningful objects without any form of annotations.</p>
        </td>
    </tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/xhh_images/2_mm.png" alt="clean-usnob" width="160" height="80">
        </td>
        <td width="75%" valign="middle">
            <a href="https://arxiv.org/pdf/2207.11699">
                <span class="papertitle">Semi-supervised Deep Multi-view Stereo</span>
            </a>
            <br>
            Hongbin Xu, Weitao Chen, Yang Liu, Zhipeng Zhou, <strong>Haihong Xiao</strong>, Baigui Sun, Xuansong Xie, Wenxiong Kang
            <br>
            <em>Proceedings of the 31st ACM International Conference on Multimedia (ACM MM)</em>, 2023
            <p>We explore the problem of learning-based MVS in a semi-supervised setting that only a tiny part of the MVS data is attached with dense depth ground truth.</p>
        </td>
    </tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/xhh_images/2_gxj.png" alt="clean-usnob" width="160" height="120">
        </td>
        <td width="75%" valign="middle">
            <a href="https://ope.lightpublishing.cn/zh/article/doi/10.37188/OPE.20233105.0667/">
                <span class="papertitle">Key techniques for three-dimensional completion: a review</span>
            </a>
            <br>
            <strong>Haihong Xiao</strong>,  Qiuxia Wu, Yuqiong Li, Wenxiong Kang
            <br>
            <em>Optics and Precision Engineering</em>, 2023
            <p>The inference of complete 3D shape and semantic scene information from partial observations is crucial for various applications, such as autonomous driving，robotic vision，and metaverse ecosystem construction.</p>
        </td>
    </tr>

    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/xhh_images/2_jix.png" alt="clean-usnob" width="160" height="90">
        </td>
        <td width="75%" valign="middle">
            <a href="http://www.j-csam.org/jcsam/article/abstract/20210116?st=search">
                <span class="papertitle">Estimation Algorithm of Leaf Shape Parameters of Scirpus sibiricum Based on MRE-PointNet and Autoencoder Model</span>
            </a>
            <br>
            Haoyun Wang, <strong>Haihong Xiao</strong>, Shihang Ma, Lin Chen, Jiangbo Wang, Huanliang Xu
            <br>
            <em>Trans Chin Soc Agric Mach</em>, 2021
        </td>
    </tr>
    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/xhh_images/2_jixpc.png" alt="clean-usnob" width="160" height="80">
        </td>
        <td width="75%" valign="middle">
            <a href="http://www.j-csam.org/jcsam/article/abstract/20210916?st=search">
                <span class="papertitle">Point cloud complementation method of Epipremnum aureum leaves under occlusion conditions based on MSF-PPD network</span>
            </a>
            <br>
            <strong>Haihong Xiao</strong>, Huanliang Xu, Shihang Ma, Ling  Chen, Jiangbo Wang, Haoyun Wang
            <br>
            <em>Trans Chin Soc Agric Mach</em>, 2021
        </td>
    </tr>

<tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/xhh_images/2_cl.png" alt="clean-usnob" width="160" height="80">
    </td>
    <td width="75%" valign="middle">
        <a href="http://www.tcsae.org/cn/article/Y2021/I13/172">
            <span class="papertitle">Estimation of external phenotypic parameters of Bunting leaves using FL-DGCNN model</span>
        </a>
        <br>
        Ling Chen, Haoyun Wang, <strong>Haihong Xiao</strong>, Shihang Ma, Yao Yang, Huanliang Xu
        <br>
        <em>Transactions of the Chinese Society of Agricultural Engineering</em>, 2021
    </td>
</tr>

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/xhh_images/2_act.png"></td>
              <td width="75%" valign="center">
                Reviewer for IEEE Transactions on Visualization and Computer Graphics
                <br>
                  Reviewer for IEEE Transactions on Circuits and Systems for Video Technology
                <br>
                  Reviewer for ACM International Conference on Multimedia
                <br>
                  Reviewer for IEEE Internet of Things Journal
                <br>
                  Reviewer for Pattern Recognition
                <br>
                  Reviewer for Neural Networks
                  <br>
                  Reviewer for Knowledge-based Systems
                  <br>
                  Reviewer for Neurocomputing
                  <br>
                  Reviewer for Pattern Recognition and Computer Vision
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/xhh_images/2_awards.png" alt="cs188">
              </td>
              <td width="75%" valign="center">
                  National Scholarship, 2024
                <br>
                  President's Scholarship, South China University of Technology, 2024
                  <br>
                  President's Scholarship, South China University of Technology, 2023
                <br>
                  Outstanding Graduate Award, Nanjing Agricultural University, 2021</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                 This webpage template was recycled from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
